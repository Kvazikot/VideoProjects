  + - - - + - + - -
  + - + - + copyright by Vladimir Baranov (Kvazikot)  <br>
  + - + - + email: vsbaranov83@gmail.com  <br>
  + - + - + github: http://github.com/Kvazikot/VideoProjects <br>
```
                            )            (
                           /(   (\___/)  )\
                          ( #)  \ ('')| ( #
                           ||___c\  > '__||
                           ||**** ),_/ **'|
                     .__   |'* ___| |___*'|
                      \_\  |' (    ~   ,)'|
                       ((  |' /(.  '  .)\ |
                        \\_|_/ <_ _____> \______________
                         /   '-, \   / ,-'      ______  \
                b'ger   /      (//   \\)     __/     /   \
                                            './_____/
```              
  
| Activity | Reward |
|---|---|
|Punishment for not inovating  |-80 |
|Punishment for trying inovating but failing | -5 |
| Reward for successful inovation | 100000 |

Дата создания документа: 02 сентября 2021 года

Оценка времени разработки: 2-3 Года

# Стадии развития проекта
2021-2023 г. Первый прототип (рабочее название VideoCubeGUI) должен получать на входе произвольный текст.
Находить хеш теги в ютьюбе и собирать конечный клип без спец. эффектов с голосом читающим текст. 

2022-2025 г. Второй прототип (отдельная ветка в гите) предполагает командную работу над спец. эффектами.
Набор стандартных переходов между клипами. Эти спецэффекты удобно реализовывать в виде dll - плагинов.
Каждый разработчик может добавлять в проект новые плагины.<br/>

2022-2023 г. Третий прототип (косольное приложение VideoCube). Облачный вариант ПО.
В этом прототипе необходимо реализовать параллельную обработку источников с перспективой запуска в облачной среде.

# Требования к интерфейсу GUI.
* r451. Интерфейс VideoCubeCV должен быть реализован на Qt.
* r452. По сути он должен напоминать текстовый редактор поддерживающий html (компонент QTextEdit).
* r453. Весь алгоритм можно разбить на несколько больших этапов, каждому из которых соответсвует отдельное меню в GUI или кнопка.<br/>
    * r454.1. QAction. Найти и подсветить ключевые слова (или хештеги).
    * r455.2. QAction. Скачать источнки изи ютьюба, где встречаются подсвеченные слова.
    * r456.3. QAction. Добавиить озвучку в форме речи + музыка      
    * r456.4. QAction. Собрать несколько вариантов клипов.
    * r456.5. QAction. Просмотреть полученные клипы.
    * r456.6. QAction. Загрузить видеоклипы на выбранные видеохостинги
    


# Желательно реализовать:

* r1. Весь софт должен быть разработан с учетом его использования в realtime стримах.
* r2. Весь софт должен быть многократно использоваться в разных контекстах и разных эпизодов футурологического научного подкаста. 
* r2.1. Софт должен быть по возможности GPU-optimized особенно то что касается фильтров и спец.эффектов
* r3. Софт должен использовать gstreamer framework.
* r4. Принцип Оккама. Программист работает с текстом или описанием нужного контента, а не с монтажным столом и его странностями
* r5. Полностью автономный софт скрипт для монтажки разных вариантов видео возможно для раных категорий людей или контекстов. 
* r6. Высокая плотность упаковки информации характерная для Discovery, PBS Nova и др эталонных научных каналов. 
* r7. Приветсвуются вставки на 3д сцены из разных sf фильмов. Обойти автоматический копирайт чеккер можно, используя эффект кубика рубика или другие геометрические искажения. Перевод видео в аски коды смотри [QuasiCode](https://github.com/Kvazikot/QuasiCode/blob/master/QuasiCode_EncoderDoc.MD) 
* r8. В перспективе нужно конечно создавать свои 3д сцены, но из-за их дороговизны для раскрутки канала можно использовать контент ютьюба
* r9. Изменение голоса. Мой голос похож ближе к задроту чем к Геродоту.
* r10. Какая-нибудь говорящая 3д голова.
* r11. Формальный язык построения видеоконтента на основе текста с учетом возможностей систем Codex (GPT-3)
* r12. Принцип неопределенности Гейзенберга работает в нашу пользу когда вы хотите изменить историю человечества, меняя всего один байт описания вашего видеоконтента
* r13. Предоставить возможность запланировать удобное время для творческой работы, возложив на компьютер всю рутину. 
* r14. Софт должен сохранять как можно больше нервных клеток его пользователя.
* r14. Возможность добавлять эмоциональный окрас видео и музыки. Грусный или веселый. 
    * r15. Пользователь дает на входе список желаемой музыки. Алгоритм выбирает из этого списка те треки которые подходят под основную эмоцию видео.  
    * r16. Нужна большая база данных с хештегами чтобы составить конечный материал.
* r15. Аудио реального чтеца будет использоваться с произвольными паузами между фразами \ абзацами. Технология video grep.
* r15-1. Аудио синтезированного голоса читающим текст генерируется с помощью синтезатора google, microsoft, yandex.



# Общий алгоритм создания видео контента для youtube
1. Сначала готовится текст выпуска. 
2. Он записывается голосом с помощью bandicam с полного экрана (f11 в хроме) захватом экрана текста. <br/>
   При диктовке текста можно выделять место в тексте где я читаю <br/>
   Это нужно для того чтобы можно было прочитать тайм код и синхронизировать видео ряд с текстом <br/>
3. Разметка таймкода. Выгрузить файл субтитров из youtube.
5. Альтернативный вариант - использование синтезатора речи Google. Смотри секцию вопросы.
6. По тексту скрипт находит необходимый видеоконтент в ютьюбе 
7. Готовлю список видео с такой табличкой 

Номер | URL | Название | Продолжительность | Эффект перехода |
|---|---|---|---|---|


4. Размечаю в тексте места где какой ролик идет 
5. Добавляю прямо в текст список видео и эффектов [source1,source2,source3]<3d cube, fade_in>
6. Запускаю пайтоновский скрипт через VideoCubeGUI использующий [MoviePy](https://zulko.github.io/moviepy/install.html), 
который в идеале пройдет по тексту или табличке и составит готовое видео.
Например прямо в табличке можно с помощью ключевого слова обозначать переход между видео.
7. Звук берется из видео подготовленного на 1 этапе.
8. Далее в скрипте нужно предусмотреть стандартные лейблы с надписями.
Шрифты можно взять из веба. 
[Автоматизация фотошопа через пайтон](https://martechwithme.com/photoshop-scripting-with-python-on-windows/)
9. Все это приправляется наложением тумана, клеточных автоматов

Пример текста для с правилами обработки и описанием контента находится [здесь](https://github.com/Kvazikot/VideoProjects/edit/master/Prob_Terminator_scenario/text_with_clip_insertion.MD)

# Программа VideoCube
Реализована на Unity и способна принять через Беркли Волны т.е. Беркли Сокеты команды от VideoCubeCore. 
VdeoCube - это коллекция программ. Исторически первый 3д эффект с использованием кадров видео переданных по сокетам от пайтон программы.
Идея кубика рубика где вместо цветных суб-кубиков представлены телевизоры с кадрами видео.


# Общая схема пайплайна для подготовки конечного ролика
Пайплайн выглядит примерно так
1.  VideoCubeCore читает данное описание, скрипт субтитров и видео с моим голосом .
2.  Находит теги с источниками описанными в тексте.
3.  Загружает видео с ютьюба от нужной позиции
4.  Разбивает текст на абзацы.
5.  Расчитывает сколько времени нужно заполнить видеоконтентом для данного абзаца.
6.  Создает в numpy.hstack исзображение 6 кадров из 6 разных видеоисточников
7.  Добавляет текст в рамку отрендеренный скриптом text_realtime_vfx.py и photoshop_render.py 
8.  Стыкует кадры от разных источников пишет все в файл paragraph1.mp4
9.  Запускает приложение на Unity (например VideoCube).  
10.  Передает ему изображение кадра через shared memory, sockets или это приложение само читает видеофайл.
11.  Приложение Unity (нпример VideoCube) рендерит нужный 3д эффект
12.  Подготовка голоса диктора. Через технологию video_grep MoviePy разбивает аудио по фрагментам распознанного текста и вставляет нужный текст
13.  Добавляет музыкальное сопровождение см. r14.
14.  Подготавливает следующее видео.

# Диаграмма общего взаимодействия ПО VideoCube с использованием только Qt и app7CoreLib 
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram_App7.png)

# Диаграмма общего взаимодействия ПО VideoCube с подключением Unity через shared memory 
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram.png)

# Диаграмма общего взаимодействия ПО VideoCube с использованием MoviePy
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram_Python.png)
<b>Преимущества этой схемы:</b>
* p44.1. Пайтон код легко читать и легко сгенерировать
* p44.2. Присутствие Unity в цепочке 3д рендеринга повышает шансы на развитие проекта по поути генератора 3д сцен

<b>Недостатки это схемы:</b>
* m44.1. Использование Python снижает производительность
* m44.2. Использование сразу 3 языков (си++, Python, c# ). Неудобно поддерживать и развивать код.

# Диаграмма общего взаимодействия ПО VideoCube с использованием [OpenShotLibrary](https://github.com/OpenShot/libopenshot)
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram_OpenShot.png)
<b>Недостатки этой схемы:</b>
* 
* 
<b>Преимущества этой схемы:</b>
* p55.1. Существование опен сорсного редактора видео на основе библиотеки [OpenShotLibrary](https://github.com/OpenShot/libopenshot)
* p55.2. Отсутствие Unity в цепочке 3д рендеринга упрощает установку и вообще распространение софта
* p55.3. Присутствие пайтон биндингов в OpenShotLibrary позволяет генерировать код на пайтоне.

# Протокол подготовоки видео ролика к загрузке на ютьюб
На выходе мы получаем 5-10 видеороликов с разным содержанием. Это удобно на даче с узким каналом.

# Основная задача софта. Выйграть время
В эпоху опиумных войн важна каждая секунда.
Поэтому нужно предоставить открытое АПИ всему софту чтобы можно было в любой момент повлиять на окончательный монтаж изменив минимум бит.
Т.е. поощеряется написание наиболее общих описаний подходящих для разных контекстов и сцен.
Им присваивается наибольший приоритет.

# Захват внимания пользователя.
Если цель проекта промывка мозгов, чего я лично не сторонник.
То можно вставлять гиптотические теги внутри описания видео. Чтобы перехватить внимание пользователя.
Нужно ввести ограничение на эту функцию. Наша цель не промывка мозгов, а воспитание критически мыслящих людей.
Даже если человек законченный зомби, нужно пробудить в нем желание мыслить критически.
Т.е. нам нужно использовать часть технологии, говоря метафорически, темной стороны смлы, но в других целях. 
Чтобы запустить в его личности обратный процесс дезомбификации и превращении в нормального человека.

В двух словах работа с софтом должна заключаться в формировке описания и запуске монтажного скрипта
Поставил скрипт и ушел гулять в парк.
Приходишь проверяешь контент на ошибки, отбираешь лучшие варианты.
Загружаешь полученный конечный файл на ютьюб вручную или автоматизированно. 
Или несколько и смотришь какой ролик прибил копирайт чеккер или цензор.
Удаляешь локальные ролики не прошедшие проверку.

Хотя на первом этапе для обкатки софта я рекуомендую использовать платформы 
со свободой слова, где нет цензуры и втом числе копирайт чеккеров. 

# Скриншоты прототипы основнорго экрана VideoCubeGUI.
![image](https://github.com/Kvazikot/VideoProjects/blob/master/screenshots/%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA_2021_10_12_19_27_48_323.png)
![image](https://github.com/Kvazikot/VideoProjects/blob/master/screenshots/%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA_2021_10_12_19_28_01_186.png)

# Вопросы:
1. Посмотреть можно ли в пайтоне отрендерить веб шрифты?   
2. What video editing software supports python scripting? 
MoviePy + автоматизация Photoshop через ActiveX
3. How to cut and download portion of video from youtube python script?
4. How to syntesize voice python scripting with Google speech synthesis?
5. How to syntesize do voice morphing ?
6. How to connect Python3 script and Unity application using sockets?
