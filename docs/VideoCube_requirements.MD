  + - - - + - + - -
  + - + - + copyright by Vladimir Baranov (Kvazikot)  <br>
  + - + - + email: vsbaranov83@gmail.com  <br>
  + - + - + github: http://github.com/Kvazikot/VideoProjects <br>
```
                            )            (
                           /(   (\___/)  )\
                          ( #)  \ ('')| ( #
                           ||___c\  > '__||
                           ||**** ),_/ **'|
                     .__   |'* ___| |___*'|
                      \_\  |' (    ~   ,)'|
                       ((  |' /(.  '  .)\ |
                        \\_|_/ <_ _____> \______________
                         /   '-, \   / ,-'      ______  \
                b'ger   /      (//   \\)     __/     /   \
                                            './_____/
```              
  
| Activity | Reward |
|---|---|
|Punishment for not inovating  |-80 |
|Punishment for trying inovating but failing | -5 |
| Reward for successful inovation | 100000 |

Дата создания документа: 02 сентября 2021 года

Оценка времени разработки: 2-3 Года

# Стадии развития проекта
2021-2023 г. Первый прототип (рабочее название VideoCubeGUI) должен получать на входе произвольный текст.
Находить хеш теги в ютьюбе и собирать конечный клип без спец. эффектов с голосом читающим текст. 

2022-2025 г. Второй прототип (отдельная ветка в гите) предполагает командную работу над спец. эффектами.
Набор стандартных переходов между клипами. Эти спецэффекты удобно реализовывать в виде dll - плагинов.
Каждый разработчик может добавлять в проект новые плагины.<br/>

2022-2023 г. Третий прототип (косольное приложение VideoCube). Облачный вариант ПО.
В этом прототипе необходимо реализовать параллельную обработку источников с перспективой запуска в облачной среде.

# Требования к интерфейсу GUI.
* r452. Интерфейс должен напоминать текстовый редактор поддерживающий html. 
* r453. Весь алгоритм можно разбить на несколько больших этапов, каждому из которых соответсвует отдельное меню в GUI или кнопка.<br/>
    * r454.1. Найти и подсветить ключевые слова (или хештеги).
    * r455.2. Скачать источнки изи ютьюба, где встречаются подсвеченные слова.
    * r456.3. Добавиить озвучку в форме речи + музыка      
    * r456.4. Собрать несколько вариантов клипов.
    * r456.5. Просмотреть полученные клипы.
    * r456.6. Загрузить видеоклипы на выбранные видеохостинги
    
* Требования

# Желательно реализовать:

* r1. Весь софт должен быть разработан с учетом его использования в realtime стримах.
* r2. Весь софт должен быть многократно использоваться в разных контекстах и разных эпизодов футурологического научного подкаста. 
* r3. Софт должен использовать gstreamer framework.
* r4. Программист работает с текстом или описанием нужного контента, а не с монтажным столом и его странностями. Принцип Оккама.   
* r5. Полностью автономный софт скрипт для монтажки разных вариантов видео возможно для раных категорий людей или контекстов. 
* r6. Высокая плотность упаковки информации характерная для Discovery, PBS Nova и др эталонных научных каналов. 
* r7. Приветсвуются вставки на 3д сцены из разных sf фильмов. Обойти автоматический копирайт чеккер можно, используя эффект кубика рубика или другие геометрические искажения. Перевод видео в аски коды смотри [QuasiCode](https://github.com/Kvazikot/QuasiCode/blob/master/QuasiCode_EncoderDoc.MD) 
* r8. В перспективе нужно конечно создавать свои 3д сцены, но из-за их дороговизны для раскрутки канала можно использовать контент ютьюба
* r9. Изменение голоса. Мой голос похож ближе к задроту чем к Геродоту.
* r10. Какая-нибудь говорящая 3д голова [например synthesia](https://www.synthesia.io/features).
* r11. Формальный язык построения видеоконтента на основе текста с учетом возможностей систем Codex (GPT-3)
* r12. Принцип неопределенности Гейзенберга работает в нашу пользу когда вы хотите изменить историю человечества, меняя всего один байт описания вашего видеоконтента
* r13. Предоставить возможность запланировать удобное время для творческой работы, возложив на компьютер всю рутину. 
* r14. Софт должен сохранять как можно больше нервных клеток его пользователя.
* r14. Возможность добавлять эмоциональный окрас видео и музыки. Грусный или веселый. 
    * r15. Пользователь дает на входе список желаемой музыки. Алгоритм выбирает из этого списка те треки которые подходят под основную эмоцию видео.  
    * r16. Нужна большая база данных с хештегами чтобы составить конечный материал.
* r15. Аудио реального чтеца будет использоваться с произвольными паузами между фразами \ абзацами. Технология video grep.
* r15-1. Аудио синтезированного голоса читающим текст генерируется с помощью синтезатора google, microsoft, yandex.
* r16. VideoCubeGUI должен содержать не только текст клипа, но и код сгенерированный генератором си++ или пайтон кода.
    * Чтобы подключать codex нужно чтобы было побольше примеров кода. 
* r17. Ядро системы должно иметь не только qt-шную морду, но и веб интерфейс. 
* r18. Желательно чтобы в веб интерфейсе был какой-то прогресс бар, видео которое создает сервер.
* r19. Веб интерфейс должен содержать видео плеер.
* r20. Веб интерфейс должен содержать готовые шаблоны или примеры видеоконтента. Текст и сгенерированное по тексту видео.
* r21. Веб интерфейс должен содержать формы для настройки титров. Шрифты, цвет, специальные эффекты.
   * r21.1. причем важен именно не только ui-слайдеры, чекбоксы и кнопки, но и эквивалентное кодовое описание.
   * r21.2. вручную настроенные параметры должны быть использованы для обучения модели
* r22. Софт должен напоминать самые популярные пакеты видеоредактирования
* r23. Софт должен копировать часть функционала, которое предоставляют популярные пакеты видеоредактирования
* r24. Веб интерфейс должен предоставлять выбор музыкального трека.
* r25. На протяжении жизненного цикла ПО C++ код эвристики в софте должны замещаться функционалом нейросетей. Что в конечном итоге приведет заменой инженеров на сервисы децентрализованного искусственного интелелкта, типа openCOG.
* Т.е. закодированные в коде эвристики нужно свести к минимому в пользу методов машинного обучения.
* r26. Фича для стримов. Соофт должен уметь делать скачку видео и монтаж на лету взависимости от того что говорит пользователь в микрофон.

# Performance requirements 
* r2.1. Софт должен быть по возможности GPU-optimized особенно то что касается фильтров и спец.эффектов


# Общий алгоритм создания видео контента для youtube
1. Сначала готовится текст выпуска. 
2. Он записывается голосом с помощью bandicam с полного экрана (f11 в хроме) захватом экрана текста. <br/>
   При диктовке текста можно выделять место в тексте где я читаю <br/>
   Это нужно для того чтобы можно было прочитать тайм код и синхронизировать видео ряд с текстом <br/>
3. Разметка таймкода. Выгрузить файл субтитров из youtube.
5. Альтернативный вариант - использование синтезатора речи Google. Смотри секцию вопросы.
6. По тексту скрипт находит необходимый видеоконтент в ютьюбе 
7. Готовлю список видео с такой табличкой 

Номер | URL | Название | Продолжительность | Эффект перехода |
|---|---|---|---|---|


4. Размечаю в тексте места где какой ролик идет 
5. Добавляю прямо в текст список видео и эффектов [source1,source2,source3]<3d cube, fade_in>
6. Запускаю пайтоновский скрипт через VideoCubeGUI использующий [MoviePy](https://zulko.github.io/moviepy/install.html), 
который в идеале пройдет по тексту или табличке и составит готовое видео.
Например прямо в табличке можно с помощью ключевого слова обозначать переход между видео.
7. Звук берется из видео подготовленного на 1 этапе.
8. Далее в скрипте нужно предусмотреть стандартные лейблы с надписями.
Шрифты можно взять из веба. 
[Автоматизация фотошопа через пайтон](https://martechwithme.com/photoshop-scripting-with-python-on-windows/)
9. Все это приправляется наложением тумана, клеточных автоматов

Пример текста для с правилами обработки и описанием контента находится [здесь](https://github.com/Kvazikot/VideoProjects/edit/master/Prob_Terminator_scenario/text_with_clip_insertion.MD)

# Программа VideoCube
Реализована на Unity и способна принять через Беркли Волны т.е. Беркли Сокеты команды от VideoCubeCore. 
VdeoCube - это коллекция программ. Исторически первый 3д эффект с использованием кадров видео переданных по сокетам от пайтон программы.
Идея кубика рубика где вместо цветных суб-кубиков представлены телевизоры с кадрами видео.


# Общая схема пайплайна для подготовки конечного ролика
Пайплайн выглядит примерно так
1.  VideoCubeCore читает данное описание, скрипт субтитров и видео с моим голосом .
2.  Находит теги с источниками описанными в тексте.
3.  Загружает видео с ютьюба от нужной позиции
4.  Разбивает текст на абзацы.
5.  Расчитывает сколько времени нужно заполнить видеоконтентом для данного абзаца.
6.  Создает в numpy.hstack исзображение 6 кадров из 6 разных видеоисточников
7.  Добавляет текст в рамку отрендеренный скриптом text_realtime_vfx.py и photoshop_render.py 
8.  Стыкует кадры от разных источников пишет все в файл paragraph1.mp4
9.  Запускает приложение на Unity (например VideoCube).  
10.  Передает ему изображение кадра через shared memory, sockets или это приложение само читает видеофайл.
11.  Приложение Unity (нпример VideoCube) рендерит нужный 3д эффект
12.  Подготовка голоса диктора. Через технологию video_grep MoviePy разбивает аудио по фрагментам распознанного текста и вставляет нужный текст
13.  Добавляет музыкальное сопровождение см. r14.
14.  Подготавливает следующее видео.

# Диаграмма общего взаимодействия ПО VideoCube с использованием только Qt и app7CoreLib 
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram_App7.png)

# Диаграмма общего взаимодействия ПО VideoCube с подключением Unity через shared memory 
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram.png)

# Диаграмма общего взаимодействия ПО VideoCube с использованием MoviePy
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram_Python.png)
<b>Преимущества этой схемы:</b>
* p44.1. Пайтон код легко читать и легко сгенерировать
* p44.2. Присутствие Unity в цепочке 3д рендеринга повышает шансы на развитие проекта по поути генератора 3д сцен

<b>Недостатки это схемы:</b>
* m44.1. Использование Python снижает производительность
* m44.2. Использование сразу 3 языков (си++, Python, c# ). Неудобно поддерживать и развивать код.
* m44.3. Проект MoviePy похоже больше не двигается

# Диаграмма общего взаимодействия ПО VideoCube с использованием [OpenShotLibrary](https://github.com/OpenShot/libopenshot)
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram_OpenShot.png)

<b>Недостатки этой схемы:</b>
* m55.1 минус 1
* m55.2 минус 2
* 


<b>Преимущества этой схемы:</b>
* p55.1. Существование опен сорсного редактора видео на основе библиотеки [OpenShotLibrary](https://github.com/OpenShot/libopenshot)
* p55.2. Отсутствие Unity в цепочке 3д рендеринга упрощает установку и вообще распространение софта
* p55.3. Присутствие пайтон биндингов в OpenShotLibrary позволяет генерировать код на пайтоне.

# Протокол подготовоки видео ролика к загрузке на ютьюб
На выходе мы получаем 5-10 видеороликов с разным содержанием. Это удобно на даче с узким каналом.

# Основная задача софта. Выйграть время
В эпоху опиумных войн важна каждая секунда.
Поэтому нужно предоставить открытое АПИ всему софту чтобы можно было в любой момент повлиять на окончательный монтаж изменив минимум бит.
Т.е. поощеряется написание наиболее общих описаний подходящих для разных контекстов и сцен.
Им присваивается наибольший приоритет.

# Захват внимания пользователя.
Если цель проекта промывка мозгов, чего я лично не сторонник.
То можно вставлять гиптотические теги внутри описания видео. Чтобы перехватить внимание пользователя.
Нужно ввести ограничение на эту функцию. Наша цель не промывка мозгов, а воспитание критически мыслящих людей.
Даже если человек законченный зомби, нужно пробудить в нем желание мыслить критически.
Т.е. нам нужно использовать часть технологии, говоря метафорически, темной стороны смлы, но в других целях. 
Чтобы запустить в его личности обратный процесс дезомбификации и превращении в нормального человека.

В двух словах работа с софтом должна заключаться в формировке описания и запуске монтажного скрипта
Поставил скрипт и ушел гулять в парк.
Приходишь проверяешь контент на ошибки, отбираешь лучшие варианты.
Загружаешь полученный конечный файл на ютьюб вручную или автоматически . 
Или несколько и смотришь какой ролик прибил копирайт чеккер или цензор.
Удаляешь локальные ролики не прошедшие проверку.

Хотя на первом этапе для обкатки софта я рекуомендую использовать платформы где нет цензуры и втом числе копирайт чеккеров. 

# Функциональная схема ядра VideoCubeCV.
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_Diagram_Core.png)

<b>Недостатки этой схемы:</b>
* m75.1 
    * 
* m75.2 
* 
<b>Преимущества этой схемы:</b>
* p85.1 
* p85.2 
* 


# Блоксхема видеомонтажа
![image](https://github.com/Kvazikot/VideoProjects/blob/master/VideoCube/VideoCubeCV/diagrams/VideoCubeCore_BlockDiagram_ClipComposiion.png)

<b>Недостатки этой схемы:</b>
* m75.1 
    * 
* m75.2 
* 
<b>Преимущества этой схемы:</b>
* p85.1 
* p85.2 
* 

# Скриншоты прототипы основного экрана VideoCubeGUI.
![image](https://github.com/Kvazikot/VideoProjects/blob/master/screenshots/%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA_2021_10_12_19_27_48_323.png)
![image](https://github.com/Kvazikot/VideoProjects/blob/master/screenshots/%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA_2021_10_12_19_28_01_186.png)


<b>Недостатки этой схемы:</b>
* m65.1 Нет места для встраивания монтажной линейки для редактирования длинны клипов
    * Можно взять монтажную линейку из OpenShotEditor поскольку этот проект под лицензией GPL
* m65.2 Отсутствует место для выходного текста кодогенератора пайтона или си++
* m65.2 Отсутствует редактор vfx

<b>Преимущества этой схемы:</b>
* p65.1 Возможность ручной подгонки параметров vfx. Параметры vfx позволяют встроить ObjectInspector из app7CoreLib или тот который входит в состав Qt.
* p65.2 



# Вопросы:
1. Посмотреть можно ли в пайтоне отрендерить веб шрифты?   
2. What video editing software supports python scripting? 
MoviePy + автоматизация Photoshop через ActiveX
3. How to cut and download portion of video from youtube python script?
4. How to syntesize voice python scripting with Google speech synthesis?
5. How to syntesize do voice morphing ?
6. How to connect Python3 script and Unity application using sockets?

# [Ссылки и видео](https://github.com/Kvazikot/VideoProjects/blob/master/docs/VideoCube_links.MD)
